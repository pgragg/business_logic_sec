{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"Uyaf1-7qy5o9EJt8z_xc\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklisted_ciks = ['0001062292']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HTTParty:\n",
    "    \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def simple_get(self, url):\n",
    "        \"\"\"\n",
    "        Attempts to get the content at `url` by making an HTTP GET request.\n",
    "        If the content-type of response is some kind of HTML/XML, return the\n",
    "        text content, otherwise return None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with closing(get(url, stream=True)) as resp:\n",
    "                return resp.content\n",
    "\n",
    "        except RequestException as e:\n",
    "            log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "            return None\n",
    "\n",
    "\n",
    "    def log_error(self, e):\n",
    "        \"\"\"\n",
    "        It is always a good idea to log errors. \n",
    "        This function just prints them, but you can\n",
    "        make it do anything.\n",
    "        \"\"\"\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecentForms:\n",
    "    # Used by FilingIndex to get recent forms\n",
    "    def __init__(self, start=0, count=100):\n",
    "        rss = \"\"\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent\n",
    "                 &CIK=&type=8-K&company=&dateb=&owner=exclude&start=\"\"\"\n",
    "        rss = rss + str(start) + \"&count=\"\n",
    "        rss = rss + str(count) + \"&output=atom\"\n",
    "        res = HTTParty().simple_get(rss)\n",
    "        soup = Soup(res,'xml')\n",
    "        self.entries = soup.find_all('entry')\n",
    "        \n",
    "    def get_all(self):\n",
    "        return pd.DataFrame.from_records([Entry(entry).to_dict() for entry in self.entries])\n",
    "        \n",
    "class Entry:\n",
    "    # Wraps Soup objects with an interface that gives info on that form. \n",
    "    def __init__(self, soup_entry):\n",
    "        self.entry = soup_entry\n",
    "        return None\n",
    "        \n",
    "    def title(self):\n",
    "        title_text = self.entry.find('title').get_text()\n",
    "        return title_text.split('(')[0].split('-')[-1].strip().upper()\n",
    "    \n",
    "    def cik(self):\n",
    "        title_text = self.entry.find('title').get_text()\n",
    "        return str(title_text.split(')')[0].split('(')[-1])\n",
    "        \n",
    "    def link(self):\n",
    "        return self.entry.find('link').get_attribute_list('href')[0].replace('-index.htm', '.txt')\n",
    "        \n",
    "    def summary(self):\n",
    "        text = self.entry.find('summary').get_text()\n",
    "        return ' --- '.join(text.split('<br>')[1:]).replace(\"\\n\", '')\n",
    "        \n",
    "    def updated(self):\n",
    "        return self.entry.find('updated').get_text()\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'title': self.title(),\n",
    "            'cik': self.cik(),\n",
    "            'link': self.link(),\n",
    "            'summary': self.summary(),\n",
    "            'updated': self.updated()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecentForms(0).get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FilingIndex:\n",
    "    def __init__(self, start=0):\n",
    "        self.start = start\n",
    "        return None\n",
    "    \n",
    "    # Gets recent forms idempotently and saves to filings_index.csv\n",
    "    def update(self):\n",
    "        filings_index_df = self.get()\n",
    "        recent_filings_df = RecentForms(self.start).get_all()\n",
    "        all_filings = recent_filings_df.append(filings_index_df)\n",
    "        deduped_filings = all_filings.drop_duplicates(subset=['link'])\n",
    "        new_filing_count = len(deduped_filings) - len(filings_index_df)\n",
    "        deduped_filings.to_csv('filings_index.csv', index=False)\n",
    "        return new_filing_count\n",
    "    \n",
    "    def get(self):\n",
    "        try:\n",
    "            return pd.read_csv('filings_index.csv')\n",
    "        except: \n",
    "            return pd.DataFrame.from_dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CompanyTickerMapping:\n",
    "    # Reads from a static csv: 'company_ticker_mapping.csv'\n",
    "    def __init__(self, ticker_mapping=None):\n",
    "        if( type(ticker_mapping) == pd.core.frame.DataFrame ):\n",
    "            self.ticker_mapping = ticker_mapping \n",
    "        else:\n",
    "            self.ticker_mapping = pd.read_csv('company_ticker_mapping.csv')\n",
    "        \n",
    "    def get(self):\n",
    "        return self.ticker_mapping\n",
    "    \n",
    "    def ticker_symbol_from_cik(self, cik):\n",
    "        return self.where_equal('cik', cik).ticker_symbol.values[0]\n",
    "    \n",
    "    def where_equal(self, column, value):\n",
    "        df = self.ticker_mapping\n",
    "        return df.loc[df[column] == value]\n",
    "    def where_in(self, column, list_of_values):\n",
    "        df = self.ticker_mapping\n",
    "        return df.loc[df[column].isin(list_of_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FilingText:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    # Saves the document text of the last n filings to the local filing_texts folder\n",
    "    def update(self, num=-1):\n",
    "        updated = []\n",
    "        # Write each filing to file\n",
    "        for filing in self.ticker_symbol_dates(num):\n",
    "            ticker_symbol = filing['ticker_symbol']\n",
    "            date =  filing['date']\n",
    "            filename = filing['filename']\n",
    "            link = filing['link']\n",
    "            if os.path.isfile(filename):\n",
    "                continue\n",
    "            else:\n",
    "                updated.append(filing)\n",
    "                doc_text = str(HTTParty().simple_get(filing['link']))\n",
    "                f = open(filename,'w')\n",
    "                f.write(doc_text)\n",
    "                f.close()\n",
    "        return updated\n",
    "    \n",
    "    def ticker_symbol_dates(self, num=-1):\n",
    "        tm = CompanyTickerMapping().get()\n",
    "        # Get a list of ciks that we have stock ticker symbols for\n",
    "        ciks = tm.cik \n",
    "        # Find recent filings \n",
    "        filings = FilingsIndex().get()[:num]\n",
    "        fwks = filings.loc[filings['cik'].isin(ciks.values)]\n",
    "        output = []\n",
    "        # Write each filing to file\n",
    "        for filing in fwks.to_records():\n",
    "            ticker_symbol = CompanyTickerMapping(ticker_mapping=tm).ticker_symbol_from_cik(filing.cik)\n",
    "            date = str(filing.updated).split('T')[0]\n",
    "            filename = f'filing_texts/{ticker_symbol}_{date}'\n",
    "            output.append({'ticker_symbol': ticker_symbol, 'date': date, 'filename': filename, 'link': filing.link})\n",
    "        return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriceCsv:\n",
    "    def __init__(self):\n",
    "        self.range = range(-10, 4)\n",
    "        \n",
    "    def get(self, ticker_symbol):\n",
    "        try:\n",
    "            return pd.read_csv(f'prices/{ticker_symbol}.csv')\n",
    "        except:\n",
    "            return pd.DataFrame.from_dict({})\n",
    "        \n",
    "    def update_all(self):\n",
    "        all_tickers = FilingText().ticker_symbol_dates()\n",
    "        self.update(all_tickers)\n",
    "    \n",
    "    def update(self, list_of_objects=None):\n",
    "        # If list_of_objects isn't passed in, try to update all prices\n",
    "        for obj in list_of_objects:\n",
    "            filing_date = obj['date']\n",
    "            ticker_symbol = obj['ticker_symbol']\n",
    "            existing_prices = self.get(ticker_symbol)\n",
    "            date_range = self.__date_range(filing_date)\n",
    "            # 'Continue' here if any price in the date_range is in the future \n",
    "            if datetime.datetime.strptime(date_range[-1], '%Y-%m-%d') >= datetime.datetime.now():\n",
    "                continue\n",
    "            # 'Continue' here if date_range is filled in for this ticker_symbol in the csv. \n",
    "            if self.__is_in_range(date_range, symbol):\n",
    "                continue\n",
    "            try:\n",
    "                recent_prices = self.__av_fetch(date_range, ticker_symbol)\n",
    "            except:\n",
    "                recent_prices = self.__quandl_fetch(date_range, ticker_symbol)\n",
    "            if len(recent_prices) == 0:\n",
    "                continue\n",
    "            all_prices = recent_prices.append(existing_prices)\n",
    "            deduped_prices = all_prices.drop_duplicates(subset=['date'])\n",
    "            deduped_prices.to_csv(f'prices/{ticker_symbol}.csv', index=False)\n",
    "        return list_of_objects\n",
    "    \n",
    "    def __date_range(self, date):\n",
    "        dates = []\n",
    "        for delta in self.range:\n",
    "            date_delta = datetime.timedelta(days=delta)\n",
    "            date_string = datetime.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "            dates.append(str(date_string + date_delta))\n",
    "        return dates\n",
    "       \n",
    "    def __quandl_fetch(self, dates, symbol):\n",
    "        gte = dates[0]\n",
    "        lte = dates[-1]\n",
    "        data = quandl.get_table('WIKI/PRICES', qopts = { 'columns': ['ticker', 'date', 'close', 'open', 'high', 'low'] }, ticker = [symbol], date = { 'gte': gte, 'lte': lte })\n",
    "        return data\n",
    "    \n",
    "    def __av_fetch(self, dates, symbol):\n",
    "        url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&apikey=QPL6YTN5VA6V7MP8'\n",
    "        response = json.loads(HTTParty().simple_get(url))\n",
    "        response = response['Time Series (Daily)']\n",
    "        records = []\n",
    "        for date in dates:\n",
    "            info = response.get(date, {})\n",
    "            if len(info.keys()) == 0:\n",
    "                records.append({\n",
    "                    'date': date,\n",
    "                    'ticker': symbol,\n",
    "                    'open': 'N/A',\n",
    "                    'high': 'N/A',\n",
    "                    'low': 'N/A',\n",
    "                    'close': 'N/A'\n",
    "                 })\n",
    "                continue\n",
    "            obj = {\n",
    "                'date': date,\n",
    "                'ticker': symbol,\n",
    "                'open': info['1. open'],\n",
    "                'high': info['2. high'],\n",
    "                'low': info['3. low'],\n",
    "                'close': info['4. close']\n",
    "            }\n",
    "            records.append(obj)\n",
    "        df = pd.DataFrame.from_records(records)\n",
    "        df = df.sort_values(by='date')\n",
    "        return df\n",
    "    \n",
    "    def __is_in_range(self, date_range, symbol):\n",
    "        df = self.get(symbol)\n",
    "        try:\n",
    "            dates_included_already = len(df.loc[df['date'].isin(date_range)])\n",
    "        except:\n",
    "            dates_included_already = 0\n",
    "        return( dates_included_already == len(date_range) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cron:\n",
    "    def __init__(self, start=0):\n",
    "        self.start = start\n",
    "        return None\n",
    "    \n",
    "    def update(self):\n",
    "        total_updated = 0\n",
    "        for i in range(0, 100):\n",
    "            doc_start = i*100\n",
    "            n_updated = FilingIndex(doc_start).update()\n",
    "            objs_updated = FilingText().update(n_updated)\n",
    "            prices_updated = PriceCsv().update(objs_updated)\n",
    "            total_updated = total_updated + len(prices_updated)\n",
    "            if len(prices_updated) == 0:\n",
    "                return total_updated\n",
    "        return total_updated\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cron().update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-825-9990bf04be7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-818-9a3fb5061fce>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mn_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFilingIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mobjs_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFilingText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_updated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPriceCsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_updated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-806-06cfe2195250>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfilings_index_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mrecent_filings_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecentForms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mall_filings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecent_filings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilings_index_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdeduped_filings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_filings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-805-2df193d60f59>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, start, count)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&output=atom\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTTParty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed (src/lxml/etree.c:116662)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed (src/lxml/etree.c:116537)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult (src/lxml/etree.c:133309)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult (src/lxml/etree.c:133055)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored (src/lxml/etree.c:13244)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStart (src/lxml/etree.c:124860)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart (src/lxml/etree.c:125774)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart (src/lxml/etree.c:132052)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# print \"Start tag %s: %s\" % (name, attrs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         if (self.parse_only and len(self.tagStack) <= 1\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mendData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mstrippable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASCII_SPACES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                         \u001b[0mstrippable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(11, 10000):\n",
    "    print(len(Cron(i*100).update()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PriceCsv().update_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run this on the command line to wipe all data. Make backups first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm filing_texts/* && rm filings_index.csv && touch filings_index.csv && rm prices/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
